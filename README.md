# use Langchain & llama3.2

> use local model: llama3.2(3B) 
>