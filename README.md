# use Langchain & llama3.2

> use local model: llama3.2(3B) 
>

> 使用其他的 port number:
```bash
streamlit run main.py --server.port 8502
```